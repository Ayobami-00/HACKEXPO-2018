{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport random\nimport gc   #Gabage collector for cleaning deleted data from memory\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Create the training dataset\ntrain = []\ntest = []\nfor j in range(4):\n    img_list = ['../input/train/train/' + str(j) + '/{}'.format(i) for i in os.listdir('../input/train/train/{}'.format(j))]\n    train = train + img_list\n\ntest = ['../input/test/test/{}'.format(i) for i in os.listdir('../input/test/test/')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af2f5513a23252e4b91fdeb8398d9caa120d6ec8"},"cell_type":"code","source":"train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8eace06b42c67fc26c270123ffb2a06f2e68d89"},"cell_type":"code","source":"#Create the labels column\nlabels = []\nfor i in range(4):\n    for j in range(900):\n        labels.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97bdf16890fcb092405372312f7c39a81ed8bdd6"},"cell_type":"code","source":"#Lets declare our image dimensions\n#we are using coloured images. \nnrows = 200\nncolumns = 200\nchannels = 3  #change to 1 if you want to use grayscale image\n\n#A function to read and process the images to an acceptable format for our model\ndef read_and_process_image(list_of_images, labels):\n    \"\"\"\n    Returns 2 arrays: \n        X is an array of images\n        Y is the labels\n    \"\"\"\n    X = [] # images\n    \n    for image in list_of_images:\n#       X.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE))\n        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))\n        \n    #Convert to numpy array\n    X = np.array(X)\n    if labels == None:\n        return X\n    else:\n        y = np.array(labels)\n        return (X,y)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2626387a17a2dbc5f138d28f8c05930c4bbb2f0b"},"cell_type":"code","source":"X,y = read_and_process_image(train, labels)\nprint(\"Shape of training data:\", str(X.shape))\nprint(\"Shape of labels:\", str(y.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf8d6c052a1c04eb40ca9be3b12d0edd96e19a91"},"cell_type":"code","source":"#Randomly shuffle both arrays\nrandomize = np.arange(len(X))\nnp.random.shuffle(randomize)\nX = X[randomize]\ny = y[randomize]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0fe07bbf2f584d2860343d0094584154267f9c7"},"cell_type":"code","source":"#let's display the first 25 images\nplt.figure(figsize=(20,20))\nfor i in range(10):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X[i], cmap=plt.cm.binary)\n    plt.xlabel('Class: '+ str(y[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d195773476bde11c46623cddde1d0952639073fa"},"cell_type":"code","source":"#Lets plot the label to be sure we have 10 classes\nsns.countplot(y)\nplt.title('Labels for Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f843c59b3f7bccda179d326009f4fe59c59b454b"},"cell_type":"code","source":"#Lets split the data into train and test set\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\ny_cat = to_categorical(y)\n# X = X.reshape(len(X), 150, 150, 3)\n# X_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size=0.20, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e50aaa9d61696264677ac4e265087a6226946ec9"},"cell_type":"code","source":"ntrain = len(X)\n# nval = len(X_val)\nnum_classes = 4\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"682f99b9d1ba70ee9efb4d966c76828e6ba5a3d2"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"945f8642487230c31fc41cf21e7dfc919204d811"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(200,200,3),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\n\nmodel.add(MaxPooling2D((2, 2),padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))    \n\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1)) \n\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(512, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1)) \n\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))      \nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"567a8f084f7ca8c8a8d9ce8c8037454e0629a1c7"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb61030c57767dfe92f44ec715b4f2bd53c8d0fc"},"cell_type":"code","source":"from keras import optimizers\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"180b0fbc61441a9eca7ac941b83c66cf74fbc9c7"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd8e61a78e772d61f103c220d966ac5f143bece9"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92abb311e9cc8caf179740d8afbba7cec376bf41"},"cell_type":"code","source":"#Create the image generators\ntrain_generator = train_datagen.flow(X, y_cat,batch_size=batch_size)\n# val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e5492a56e5cf3d598637633735612cf860c5e0"},"cell_type":"code","source":"#The training part\n#We train for 64 epochs with about 100 steps per epoch\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=ntrain // batch_size,\n                              epochs=20)\n#                               validation_data=val_generator,\n#                               validation_steps=nval // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec174dc2b4c7f587050e0ba40627012d4db877f3"},"cell_type":"code","source":"#Save the model\nmodel.save_weights('model_wieghts.h5')\nmodel.save('model_keras.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1fc56930cf917d55b1e81168ecb8bbf661ac5c2"},"cell_type":"code","source":"# #get the details form the history object\n# acc = history.history['acc']\n# val_acc = history.history['val_acc']\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n\n# epochs = range(1, len(acc) + 1)\n\n# #Train and validation accuracy\n# plt.plot(epochs, acc, 'b', label='Training accurarcy')\n# plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n# plt.title('Training and Validation accurarcy')\n# plt.legend()\n\n# plt.figure()\n# #Train and validation loss\n# plt.plot(epochs, loss, 'b', label='Training loss')\n# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n# plt.title('Training and Validation loss')\n# plt.legend()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"789d9c51971dc305fc6e02bbf6800d347d63a53b"},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/sample-submission.csv')\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e50a834b7c9700a3c9a093b863f9830806a6a233"},"cell_type":"code","source":"pred_test = read_and_process_image(test, None)\n#Scale test set\npred_test = pred_test * 1./255\n\npredicted_classes = model.predict_classes(pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4660025b70b04b236c60216bd60dc275ab0918c7"},"cell_type":"code","source":"imageId = []\nfor i,id in enumerate(test):\n    imageId.append(id.split('/')[4])\n    \nsample_sub['Category'] = predicted_classes\nsample_sub['ImageID'] = imageId\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f700e1582f261020e96b861dc89717ab447fec3b"},"cell_type":"code","source":"sample_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f3da5b5cac29214235722b8ebf0437a49530559"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}